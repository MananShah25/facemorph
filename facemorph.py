# -*- coding: utf-8 -*-
"""I059_I074_I075_CV Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KveRZ5B0kaySZfWFdkLC0bZsyPRMaG87

#Steps
1. Facial landmarks recognition in both faces (Dlib).
2. Triangular Delaunay segmentation.
3. Affine transformation between the Delaunay triangles of both faces.
4. Alpha blending on the paired triangles with a given transparency.
"""

from google.colab import drive
drive.mount('/content/drive')

import dlib
import numpy as np
import cv2
from scipy.spatial import Delaunay
import os
import matplotlib.pyplot as plt
from subprocess import Popen, PIPE
from PIL import Image

def rect_contains(rect, point):
    if point[0] < rect[0]:
        return False
    elif point[1] < rect[1]:
        return False
    elif point[0] > rect[2]:
        return False
    elif point[1] > rect[3]:
        return False
    return True

def draw_delaunay(f_w, f_h, subdiv, dictionary1):
    list4 = []
    triangleList = subdiv.getTriangleList()
    r = (0, 0, f_w, f_h)
    for t in triangleList:
        pt1 = (int(t[0]), int(t[1]))
        pt2 = (int(t[2]), int(t[3]))
        pt3 = (int(t[4]), int(t[5]))
        if rect_contains(r, pt1) and rect_contains(r, pt2) and rect_contains(r, pt3):
            list4.append((dictionary1[pt1], dictionary1[pt2], dictionary1[pt3]))
    return list4

def make_delaunay(f_w, f_h, theList, img1, img2):
    rect = (0, 0, f_w, f_h)
    subdiv = cv2.Subdiv2D(rect)
    theList = theList.tolist()
    points = [(int(x[0]), int(x[1])) for x in theList]
    dictionary = {x[0]: x[1] for x in list(zip(points, range(76)))}
    for p in points:
        subdiv.insert(p)
    list4 = draw_delaunay(f_w, f_h, subdiv, dictionary)
    return list4

def calculate_margin_help(img1, img2):
    size1 = img1.shape
    size2 = img2.shape
    diff0 = abs(size1[0] - size2[0]) // 2
    diff1 = abs(size1[1] - size2[1]) // 2
    avg0 = (size1[0] + size2[0]) // 2
    avg1 = (size1[1] + size2[1]) // 2
    return [size1, size2, diff0, diff1, avg0, avg1]

def crop_image(img1, img2):
    [size1, size2, diff0, diff1, avg0, avg1] = calculate_margin_help(img1, img2)
    if size1[0] == size2[0] and size1[1] == size2[1]:
        return [img1, img2]
    elif size1[0] <= size2[0] and size1[1] <= size2[1]:
        scale0 = size1[0] / size2[0]
        scale1 = size1[1] / size2[1]
        if scale0 > scale1:
            res = cv2.resize(img2, None, fx=scale0, fy=scale0, interpolation=cv2.INTER_AREA)
        else:
            res = cv2.resize(img2, None, fx=scale1, fy=scale1, interpolation=cv2.INTER_AREA)
        return crop_image_help(img1, res)
    elif size1[0] >= size2[0] and size1[1] >= size2[1]:
        scale0 = size2[0] / size1[0]
        scale1 = size2[1] / size1[1]
        if scale0 > scale1:
            res = cv2.resize(img1, None, fx=scale0, fy=scale0, interpolation=cv2.INTER_AREA)
        else:
            res = cv2.resize(img1, None, fx=scale1, fy=scale1, interpolation=cv2.INTER_AREA)
        return crop_image_help(res, img2)
    elif size1[0] >= size2[0] and size1[1] <= size2[1]:
        return [img1[diff0:avg0, :], img2[:, -diff1:avg1]]
    else:
        return [img1[:, diff1:avg1], img2[-diff0:avg0, :]]

def crop_image_help(img1, img2):
    [size1, size2, diff0, diff1, avg0, avg1] = calculate_margin_help(img1, img2)
    if size1[0] == size2[0] and size1[1] == size2[1]:
        return [img1, img2]
    elif size1[0] <= size2[0] and size1[1] <= size2[1]:
        return [img1, img2[-diff0:avg0, -diff1:avg1]]
    elif size1[0] >= size2[0] and size1[1] >= size2[1]:
        return [img1[diff0:avg0, diff1:avg1], img2]
    elif size1[0] >= size2[0] and size1[1] <= size2[1]:
        return [img1[diff0:avg0, :], img2[:, -diff1:avg1]]
    else:
        return [img1[:, diff1:avg1], img2[diff0:avg0, :]]

def generate_face_correspondences(theImage1, theImage2):
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor('/content/drive/MyDrive/shape_predictor_68_face_landmarks.dat')
    corresp = np.zeros((68, 2))
    imgList = crop_image(theImage1, theImage2)
    list1 = []
    list2 = []
    j = 1
    for img in imgList:
        size = (img.shape[0], img.shape[1])
        if j == 1:
            currList = list1
        else:
            currList = list2

        dets = detector(img, 1)
        if len(dets) == 0:
          print("NoFaceFound")

        j = j + 1

        for k, rect in enumerate(dets):
            shape = predictor(img, rect)

            for i in range(0, 68):
                x = shape.part(i).x
                y = shape.part(i).y
                currList.append((x, y))
                corresp[i][0] += x
                corresp[i][1] += y

        currList.append((1, 1))
        currList.append((size[1] - 1, 1))
        currList.append(((size[1] - 1) // 2, 1))
        currList.append((1, size[0] - 1))
        currList.append((1, (size[0] - 1) // 2))
        currList.append(((size[1] - 1) // 2, size[0] - 1))
        currList.append((size[1] - 1, size[0] - 1))
        currList.append(((size[1] - 1), (size[0] - 1) // 2))

    narray = corresp / 2
    narray = np.append(narray, [[1, 1]], axis=0)
    narray = np.append(narray, [[size[1] - 1, 1]], axis=0)
    narray = np.append(narray, [[(size[1] - 1) // 2, 1]], axis=0)
    narray = np.append(narray, [[1, size[0] - 1]], axis=0)
    narray = np.append(narray, [[1, (size[0] - 1) // 2]], axis=0)
    narray = np.append(narray, [[(size[1] - 1) // 2, size[0] - 1]], axis=0)
    narray = np.append(narray, [[size[1] - 1, size[0] - 1]], axis=0)
    narray = np.append(narray, [[(size[1] - 1), (size[0] - 1) // 2]], axis=0)

    return [size, imgList[0], imgList[1], list1, list2, narray]

def apply_affine_transform(src, srcTri, dstTri, size):
    warpMat = cv2.getAffineTransform(np.float32(srcTri), np.float32(dstTri))
    dst = cv2.warpAffine(src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)
    return dst

def morph_triangle(img1, img2, img, t1, t2, t, alpha):
    r = cv2.boundingRect(np.float32([t]))
    tRect = []
    t1Rect = []
    t2Rect = []

    for i in range(3):
        tRect.append(((t[i][0] - r[0]), (t[i][1] - r[1])))
        t1Rect.append(((t1[i][0] - r[0]), (t1[i][1] - r[1])))
        t2Rect.append(((t2[i][0] - r[0]), (t2[i][1] - r[1])))

    mask = np.zeros((r[3], r[2], 3), dtype=np.float32)
    cv2.fillConvexPoly(mask, np.int32(tRect), (1.0, 1.0, 1.0), 16, 0)

    img1Rect = img1[r[1]:r[1] + r[3], r[0]:r[0] + r[2]]
    img2Rect = img2[r[1]:r[1] + r[3], r[0]:r[0] + r[2]]

    size = (r[2], r[3])
    warpImage1 = apply_affine_transform(img1Rect, t1Rect, tRect, size)
    warpImage2 = apply_affine_transform(img2Rect, t2Rect, tRect, size)

    imgRect = (1.0 - alpha) * warpImage1 + alpha * warpImage2

    img[r[1]:r[1] + r[3], r[0]:r[0] + r[2]] = img[r[1]:r[1] + r[3], r[0]:r[0] + r[2]] * (1 - mask) + imgRect * mask

def generate_morph_sequence(duration, frame_rate, img1, img2, points1, points2, tri_list, size, output):
    num_images = int(duration * frame_rate)
    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-r', str(frame_rate), '-s', str(size[1]) + 'x' + str(size[0]), '-i', '-', '-c:v', 'libx264', '-crf', '25', '-vf', 'scale=trunc(iw/2)*2:trunc(ih/2)*2', '-pix_fmt', 'yuv420p', output], stdin=PIPE)

    for j in range(0, num_images):
        img1 = np.float32(img1)
        img2 = np.float32(img2)
        points = []
        alpha = j / (num_images - 1)

        for i in range(0, len(points1)):
            x = (1 - alpha) * points1[i][0] + alpha * points2[i][0]
            y = (1 - alpha) * points1[i][1] + alpha * points2[i][1]
            points.append((x, y))

        morphed_frame = np.zeros(img1.shape, dtype=img1.dtype)

        for i in range(len(tri_list)):
            x = int(tri_list[i][0])
            y = int(tri_list[i][1])
            z = int(tri_list[i][2])
            t1 = [points1[x], points1[y], points1[z]]
            t2 = [points2[x], points2[y], points2[z]]
            t = [points[x], points[y], points[z]]
            morph_triangle(img1, img2, morphed_frame, t1, t2, t, alpha)

            pt1 = (int(t[0][0]), int(t[0][1]))
            pt2 = (int(t[1][0]), int(t[1][1]))
            pt3 = (int(t[2][0]), int(t[2][1]))
            cv2.line(morphed_frame, pt1, pt2, (255, 255, 255), 1, 8, 0)
            cv2.line(morphed_frame, pt2, pt3, (255, 255, 255), 1, 8, 0)
            cv2.line(morphed_frame, pt3, pt1, (255, 255, 255), 1, 8, 0)

        res = Image.fromarray(cv2.cvtColor(np.uint8(morphed_frame), cv2.COLOR_BGR2RGB))
        res.save(p.stdin, 'JPEG')

    p.stdin.close()
    p.wait()

def doMorphing(img1, img2, duration, frame_rate, output):
    [size, img1, img2, points1, points2, list3] = generate_face_correspondences(img1, img2)
    tri = make_delaunay(size[1], size[0], list3, img1, img2)
    generate_morph_sequence(duration, frame_rate, img1, img2, points1, points2, tri, size, output)

image1 = cv2.imread("/content/02.jpeg")
image2 = cv2.imread("/content/01.jpeg")
doMorphing(image1, image2, 5, 60, "morphing.mp4")